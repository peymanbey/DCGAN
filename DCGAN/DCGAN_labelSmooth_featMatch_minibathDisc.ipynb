{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dqxpAkhj7nS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "import time\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3h8mrtX8kBu8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mKt0_6eNssu"
   },
   "outputs": [],
   "source": [
    "from utils import visual_data, load_cifar10\n",
    "from networks import Generator, Discriminator, weights_init, DiscriminatorMiniBatchDiscrimination\n",
    "from trainer import  update_params\n",
    "from losses import D_loss, G_featMatch_loss, G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_fake_samples(batchSize, gen, nz, device):\n",
    "    noise = torch.randn(batchSize, nz, 1, 1,\n",
    "                        device=device)\n",
    "    \n",
    "    return gen(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xskxnRypkEud"
   },
   "outputs": [],
   "source": [
    "# Setting up constants\n",
    "# device\n",
    "ngpu = 1\n",
    "\n",
    "# single image\n",
    "imageSize = 64\n",
    "imageMean = (0.4923172 , 0.48307145, 0.4474483)\n",
    "imageStd = (0.24041407, 0.23696952, 0.25565723)\n",
    "\n",
    "# data loader\n",
    "numWorkers = 1\n",
    "batchSize = 16\n",
    "\n",
    "# Network Arch\n",
    "nc = 3 # Number of channels\n",
    "nz = 50 # Latent vector\n",
    "ngf = 16 # relates to the depth of feature maps carried through the generator\n",
    "ndf = 16 # sets the depth of feature maps propagated through the discriminator\n",
    "\n",
    "# Training\n",
    "num_epochs = 5\n",
    "\n",
    "# Adam Optimizer\n",
    "lr = .0002\n",
    "beta1 = .5\n",
    "\n",
    "# convention of the labeling for the real and the fake datasets\n",
    "## one-sided label smoothing\n",
    "real_label = .9\n",
    "fake_label = 0\n",
    "\n",
    "# label smoothing\n",
    "## insdead of real label=.9 give uniform between .8, 1\n",
    "## insdead of fake label=0 give uniform between 0, .2\n",
    "label_smoothing = True\n",
    "\n",
    "# flip labels, with probability pFlip, flip the labels passed to the discriminator\n",
    "pFlip = 0.05\n",
    "\n",
    "# if to use last two layers' features for feature matching\n",
    "double_layer = False\n",
    "\n",
    "# inner loop repetitions\n",
    "D_inner_repeat = 2\n",
    "G_inner_repeat = 1\n",
    "\n",
    "# whether to do minibatch normalization\n",
    "miniBatchDiscrimination = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2Lp2upekCtM"
   },
   "outputs": [],
   "source": [
    "# folder to store/load data\n",
    "dataFolder = Path(\"./data\")\n",
    "# Decide which device to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PLRxbq3okJCs",
    "outputId": "ace4f873-816f-45fc-e29a-f0925c7847cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifarFolder = dataFolder/\"CIFAR10\"\n",
    "# prepare data for loading\n",
    "tsfms = transforms.Compose([\n",
    "    transforms.Resize(imageSize), \n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(imageMean, imageStd)\n",
    "])\n",
    "trainLoader, test_loader = load_cifar10(cifarFolder, tsfms, batchSize, numWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUk5fKx7kcG8"
   },
   "outputs": [],
   "source": [
    "# init D and G network\n",
    "gen = Generator(ngpu, nz, ngf, nc).to(device)\n",
    "gen.apply(weights_init);\n",
    "\n",
    "if not miniBatchDiscrimination:\n",
    "    disc = Discriminator(ngpu, nc, ndf).to(device)\n",
    "else: \n",
    "    disc = DiscriminatorMiniBatchDiscrimination(ngpu, nc, ndf).to(device)\n",
    "\n",
    "disc.apply(weights_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkBmVf4QkjyB"
   },
   "outputs": [],
   "source": [
    "# setup optmization \n",
    "optimizerD = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizerD = torch.optim.SGD(disc.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizerG = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k_Ianu2iNste",
    "outputId": "9f9141a5-27bb-4e9e-e616-a63a96ade81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    }
   ],
   "source": [
    "# fixed noise z for viusalization of the progress of the training\n",
    "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "\n",
    "# training loop \n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "7qFTS_GRkm8a",
    "outputId": "4af50b09-ad79-4b85-a6c5-d31463d14153"
   },
   "outputs": [],
   "source": [
    "current = time.time()\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the trainLoader\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################   \n",
    "        for _ in range(D_inner_repeat):\n",
    "            # real batch and fake batch\n",
    "            real_batch = data[0].to(device)\n",
    "            fake_batch = batch_fake_samples(real_batch.size(0), gen, nz, device)\n",
    "            \n",
    "            # forward pass\n",
    "            output_real, f1real, f2real = disc(real_batch)\n",
    "            output_fake, _, _ = disc(fake_batch.detach())\n",
    "            \n",
    "            # loss for D\n",
    "            errD = D_loss(output_real, output_fake, \n",
    "                          real_label, fake_label, \n",
    "                          pFlip, label_smoothing,\n",
    "                          device)\n",
    "            \n",
    "            # backward pass and optimization step\n",
    "            update_params(optimizerD, errD)\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        for _ in range(G_inner_repeat):\n",
    "            # fake batch \n",
    "            output_real, f1real, f2real = disc(real_batch)\n",
    "            fake_batch = batch_fake_samples(real_batch.size(0), gen, nz, device)\n",
    "            \n",
    "            # forward pass\n",
    "            output, f1fake, f2fake = disc(fake_batch)\n",
    "            \n",
    "            # loss function\n",
    "            errG = G_featMatch_loss(f1fake, f2fake, \n",
    "                                    f1real.detach(), f2real.detach(), double_layer)\n",
    "            \n",
    "            errG += .1*G_loss(output, real_label, label_smoothing, device)\n",
    "            \n",
    "            # backward pass and optimization step\n",
    "            update_params(optimizerG, errG)\n",
    "\n",
    "        ###########################\n",
    "        # (3) save and print progress\n",
    "        ###########################\n",
    "        # for progress prints\n",
    "        D_x = output_real.mean().item()\n",
    "        D_G_z1 = output_fake.mean().item()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[{:0>2}/{:0>2}][{:0>4}/{:0>4}]\\tLoss_D: {:.3f}\\tLoss_G: {:.3f}\\tD(x): {:.3f}\\tD(G(z)): {:.3f} / {:.3f}\\t t={:6.3f}'.format(\n",
    "                epoch, num_epochs, i, len(trainLoader),errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, time.time()-current, prec=3))\n",
    "            current = time.time()\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(trainLoader)-1)):\n",
    "            clear_output()\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qLtlQG2Cuq_d",
    "outputId": "5e0a5fb4-8e0c-40a3-9c54-431a14d6ed3b"
   },
   "outputs": [],
   "source": [
    "len(G_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "8YYEjo5OkoEk",
    "outputId": "8e5f5a1c-616c-4ef4-c63b-e7b6325273a6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxJ8XxdMsAJA"
   },
   "outputs": [],
   "source": [
    "trainIter = iter(trainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "Vx82QqQkply8",
    "outputId": "b4b7519b-421b-48ab-9a4b-349e50adffb7"
   },
   "outputs": [],
   "source": [
    "real_batch = next(trainIter)\n",
    "\n",
    "noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "fake = gen(noise).detach().cpu()\n",
    "fake = vutils.make_grid(fake, padding=2, normalize=True)\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(fake,(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCSyfMG9NsuJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_OKOGJwNm8a"
   },
   "outputs": [],
   "source": [
    "# print(optimizerD, optimizerG, trainLoader.batch_size, ngf, ndf, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8QwN3iUPoq6"
   },
   "outputs": [],
   "source": [
    "# genParams = gen.state_dict()\n",
    "# discParams = disc.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRqY8SLcINBM"
   },
   "outputs": [],
   "source": [
    "# def dumpAndDL(variable, fileName):\n",
    "#     with open(fileName, 'wb') as f:\n",
    "#         pickle.dump(variable,\n",
    "#                     f)\n",
    "#         files.download(fileName)\n",
    "        \n",
    "# def chunks(lst, n):\n",
    "#     \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "#     for i in range(0, len(lst), n):\n",
    "#         yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FY8XW6FkNsuh"
   },
   "outputs": [],
   "source": [
    "# dumpAndDL(\n",
    "#     {'genParams': genParams,\n",
    "#      'discParams': discParams,\n",
    "#     },\n",
    "#     'bestParams.p'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svnToVfYNsum"
   },
   "outputs": [],
   "source": [
    "# dumpAndDL(\n",
    "#     {'G_losses': G_losses,\n",
    "#      'D_losses':D_losses,\n",
    "#      },\n",
    "#      'losses.p'\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nqCIwtfNsut"
   },
   "outputs": [],
   "source": [
    "# n=50\n",
    "# for idx, chunk in enumerate(chunks(img_list, n)):\n",
    "#     fileName = 'img_list_{}.p'.format(idx)\n",
    "#     dumpAndDL(\n",
    "#         chunk,\n",
    "#         fileName\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OgfaMzdNsuz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94aJQJipNsu6"
   },
   "outputs": [],
   "source": [
    "# # load params to networks\n",
    "# fileName = 'bestParams.p'\n",
    "# netParams = None\n",
    "# with open(fileName, 'rb') as f:\n",
    "#      netParams = pickle.load(f)\n",
    "# gen.load_state_dict(netParams['genParams'])\n",
    "# disc.load_state_dict(netParams['discParams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wTK5eAJNsvA"
   },
   "outputs": [],
   "source": [
    "# # load params to networks\n",
    "# fileNames = ['img_list_0.p', 'img_list_1.p', 'img_list_2.p', 'img_list_3.p']\n",
    "\n",
    "# img_list = []\n",
    "# for fileName in fileNames:\n",
    "#     with open(fileName, 'rb') as f:\n",
    "#         img_list += pickle.load(f)['img_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMgx41BCNsvG"
   },
   "outputs": [],
   "source": [
    "# len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLZsogeqNsvP"
   },
   "outputs": [],
   "source": [
    "# #%%capture animation\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# plt.axis(\"off\")\n",
    "# ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list[:100]]\n",
    "# ani = animation.ArtistAnimation(fig, ims, interval=100, repeat_delay=1000, blit=True)\n",
    "\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# # writer = animation.writers['ffmpeg']\n",
    "# # ani.save('im.mp4', writer=writer, dpi=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dcgan_faster",
   "language": "python",
   "name": "dcgan_faster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
