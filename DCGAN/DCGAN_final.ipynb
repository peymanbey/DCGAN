{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dqxpAkhj7nS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "import time\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3h8mrtX8kBu8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9y27beeRHqH"
   },
   "outputs": [],
   "source": [
    "from utils import visual_data, load_cifar10\n",
    "from networks import Generator, Discriminator, weights_init, DiscriminatorMiniBatchDiscrimination, DCGAN\n",
    "from trainer import  update_params\n",
    "from losses import D_loss, G_featMatch_loss, G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "E43foEsWRHqK",
    "outputId": "5c4c44ea-a812-4686-aaf6-60953eac5603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 15 21:55:03 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 960     Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   47C    P0    39W / 128W |    576MiB /  4040MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1062      G   /usr/lib/xorg/Xorg                           205MiB |\r\n",
      "|    0      2024      G   compiz                                       114MiB |\r\n",
      "|    0      2479      G   ...uest-channel-token=13827739854444781584   165MiB |\r\n",
      "|    0      2954      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files    83MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xskxnRypkEud"
   },
   "outputs": [],
   "source": [
    "# Setting up constants\n",
    "# device\n",
    "ngpu = 1\n",
    "\n",
    "# single image\n",
    "imageSize = 64\n",
    "imageMean = (0.4923172 , 0.48307145, 0.4474483)\n",
    "imageStd = (0.24041407, 0.23696952, 0.25565723)\n",
    "\n",
    "# data loader\n",
    "numWorkers = 3\n",
    "batchSize = 16\n",
    "\n",
    "# Network Arch\n",
    "nc = 3 # Number of channels\n",
    "nz = 100 # Latent vector\n",
    "ngf = 64 # relates to the depth of feature maps carried through the generator\n",
    "ndf = 64 # sets the depth of feature maps propagated through the discriminator\n",
    "\n",
    "# Training\n",
    "num_epochs = 5\n",
    "\n",
    "# Adam Optimizer\n",
    "lr = .0002\n",
    "beta1 = .5\n",
    "\n",
    "# convention of the labeling for the real and the fake datasets\n",
    "## one-sided label smoothing\n",
    "real_label = .9\n",
    "fake_label = 0\n",
    "\n",
    "# label smoothing\n",
    "## insdead of real label=.9 give uniform between .8, 1\n",
    "## insdead of fake label=0 give uniform between 0, .2\n",
    "label_smoothing = True\n",
    "\n",
    "# flip labels, with probability pFlip, flip the labels passed to the discriminator\n",
    "pFlip = 0.05\n",
    "\n",
    "# if to use last two layers' features for feature matching\n",
    "double_layer = True\n",
    "\n",
    "# whether to do minibatch normalization\n",
    "miniBatchDiscrimination = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2Lp2upekCtM"
   },
   "outputs": [],
   "source": [
    "# folder to store/load data\n",
    "dataFolder = Path(\"./data\")\n",
    "# Decide which device to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PLRxbq3okJCs",
    "outputId": "e0abf30c-c81c-4259-f089-05b9abd0469f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifarFolder = dataFolder/\"CIFAR10\"\n",
    "# prepare data for loading\n",
    "tsfms = transforms.Compose([\n",
    "    transforms.Resize(imageSize), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imageMean, imageStd)\n",
    "])\n",
    "trainLoader, test_loader = load_cifar10(cifarFolder, tsfms, batchSize, numWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUk5fKx7kcG8"
   },
   "outputs": [],
   "source": [
    "# init D and G network\n",
    "gen = Generator(ngpu, nz, ngf, nc).to(device)\n",
    "gen.apply(weights_init);\n",
    "\n",
    "if not miniBatchDiscrimination:\n",
    "    disc = Discriminator(ngpu, nc, ndf).to(device)\n",
    "else: \n",
    "    disc = DiscriminatorMiniBatchDiscrimination(ngpu, nc, ndf).to(device)\n",
    "\n",
    "disc.apply(weights_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(gen, disc, device, \n",
    "              real_label, fake_label, pFlip, label_smoothing, double_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkBmVf4QkjyB"
   },
   "outputs": [],
   "source": [
    "# setup optmization \n",
    "optimizerD = torch.optim.Adam(dcgan.discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizerD = torch.optim.SGD(disc.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizerG = torch.optim.Adam(dcgan.generator.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9QA1Z_ZTRHqc",
    "outputId": "207dc873-b032-4e25-bc77-ab54a0dd650e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    }
   ],
   "source": [
    "# fixed noise z for viusalization of the progress of the training\n",
    "fixed_noise = torch.randn(batchSize, dcgan.generator.nz, 1, 1, device=device)\n",
    "\n",
    "# training loop \n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "g=0\n",
    "print(\"Starting Training Loop...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOkmDmzKQ7Gi"
   },
   "outputs": [],
   "source": [
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0000/3125]  Loss_D: 0.664  Loss_G: 1.011 t= 0.095\n",
      "[0050/3125]  Loss_D: 0.711  Loss_G: 0.995 t= 0.600\n",
      "[0100/3125]  Loss_D: 0.689  Loss_G: 1.018 t= 0.612\n",
      "[0150/3125]  Loss_D: 0.795  Loss_G: 0.918 t= 0.546\n",
      "[0200/3125]  Loss_D: 0.697  Loss_G: 0.979 t= 0.615\n",
      "[0250/3125]  Loss_D: 1.787  Loss_G: 0.000 t= 0.603\n",
      "[0300/3125]  Loss_D: 1.897  Loss_G: 0.000 t= 0.584\n",
      "[0350/3125]  Loss_D: 0.734  Loss_G: 0.896 t= 0.566\n",
      "[0400/3125]  Loss_D: 0.715  Loss_G: 0.995 t= 0.603\n",
      "[0450/3125]  Loss_D: 0.621  Loss_G: 0.977 t= 0.525\n",
      "[0500/3125]  Loss_D: 0.619  Loss_G: 0.999 t= 0.584\n",
      "[0550/3125]  Loss_D: 0.718  Loss_G: 0.965 t= 0.604\n",
      "[0600/3125]  Loss_D: 0.682  Loss_G: 0.917 t= 0.596\n",
      "[0650/3125]  Loss_D: 0.727  Loss_G: 0.903 t= 0.607\n",
      "[0700/3125]  Loss_D: 0.597  Loss_G: 0.971 t= 0.625\n",
      "[0750/3125]  Loss_D: 1.502  Loss_G: 0.000 t= 0.544\n",
      "[0800/3125]  Loss_D: 0.720  Loss_G: 0.883 t= 0.599\n",
      "[0850/3125]  Loss_D: 0.598  Loss_G: 0.951 t= 0.615\n",
      "[0900/3125]  Loss_D: 0.717  Loss_G: 0.875 t= 0.691\n",
      "[0950/3125]  Loss_D: 2.418  Loss_G: 0.000 t= 0.615\n",
      "[1000/3125]  Loss_D: 0.710  Loss_G: 0.893 t= 0.565\n",
      "[1050/3125]  Loss_D: 0.681  Loss_G: 0.957 t= 0.655\n",
      "[1100/3125]  Loss_D: 0.673  Loss_G: 0.966 t= 0.613\n",
      "[1150/3125]  Loss_D: 0.686  Loss_G: 0.953 t= 0.602\n",
      "[1200/3125]  Loss_D: 0.628  Loss_G: 0.935 t= 0.601\n",
      "[1250/3125]  Loss_D: 0.717  Loss_G: 0.879 t= 0.585\n",
      "[1300/3125]  Loss_D: 0.667  Loss_G: 0.934 t= 0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Process Process-6:\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f64b35538b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrainer_GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizerD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizerG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project/PHD_Implementations/DCGAN/DCGAN/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             print(\"epoch {}/{} time {}\".format(\n",
      "\u001b[0;32m~/project/PHD_Implementations/DCGAN/DCGAN/gan.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0merrD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/PHD_Implementations/DCGAN/DCGAN/gan.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0merrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0merrD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0merrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# if discriminator loss is low enough, trian generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/PHD_Implementations/DCGAN/DCGAN/gan.py\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                            fake_batch.detach())\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0merrD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/PHD_Implementations/DCGAN/DCGAN/gan.py\u001b[0m in \u001b[0;36mupdate_params\u001b[0;34m(self, optimizer, loss)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dcgan_faster/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dcgan_faster/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rainbow/miniconda3/envs/dcgan_faster/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from gan import trainer_GAN\n",
    "trainer = trainer_GAN(dcgan, trainLoader, optimizerD, optimizerG)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "7qFTS_GRkm8a",
    "outputId": "a5989b4c-86d3-42fc-ee94-819c4801ce5d"
   },
   "outputs": [],
   "source": [
    "g=0\n",
    "# For each epoch\n",
    "current = time.time()\n",
    "# for each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################   ` \n",
    "\n",
    "        # real batch and fake batch\n",
    "        real_batch = data[0].to(device)\n",
    "        fake_batch = dcgan.fake_batch(real_batch.size(0))\n",
    "        \n",
    "        errD = dcgan.discriminator_loss(real_batch, fake_batch)\n",
    "        \n",
    "        update_params(optimizerD, errD)\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        if errD.item() < .8 or g==0:\n",
    "            g += 1\n",
    "            fake_batch = dcgan.fake_batch(real_batch.size(0))\n",
    "            \n",
    "            errG = dcgan.generator_loss(real_batch, fake_batch)\n",
    "\n",
    "            update_params(optimizerG, errG)\n",
    "\n",
    "        ###########################\n",
    "        # (3) save and print progress\n",
    "        ###########################\n",
    "#         # for progress prints\n",
    "#         D_x = output_real.mean().item()\n",
    "#         D_G_z1 = output_fake.mean().item()\n",
    "#         D_G_z2 = output.mean().item()\n",
    "        \n",
    "#         # Output training stats\n",
    "#         if i % 50 == 0:\n",
    "#             print('[{:0>2}/{:0>2}][{:0>4}/{:0>4}]  Loss_D: {:.3f}  Loss_G: {:.3f}  D(x): {:.3f}  D(G(z)): {:.3f} / {:.3f}  t={:6.3f}  iterG={}/50'.format(\n",
    "#                 epoch, num_epochs, i, len(trainLoader),errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, time.time()-current, g, prec=3))\n",
    "#             g = 0\n",
    "#             current = time.time()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('[{:0>4}/{:0>4}]  Loss_D: {:.3f}  Loss_G: {:.3f} t={:6.3f}'.format(\n",
    "                    i, len(trainLoader), errD, errG, time.time()-current, prec=3))\n",
    "            g = 0\n",
    "            current = time.time()\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "#         G_losses.append(errG.item())\n",
    "#         D_losses.append(errD.item())\n",
    "\n",
    "#         # Check how the generator is doing by saving G's output on fixed_noise\n",
    "#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(trainLoader)-1)):\n",
    "#             clear_output()\n",
    "#             with torch.no_grad():\n",
    "#                 fake = gen(fixed_noise).detach().cpu()\n",
    "#             img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "7qFTS_GRkm8a",
    "outputId": "a5989b4c-86d3-42fc-ee94-819c4801ce5d"
   },
   "outputs": [],
   "source": [
    "g=0\n",
    "# For each epoch\n",
    "current = time.time()\n",
    "# for each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################   ` \n",
    "\n",
    "        # real batch and fake batch\n",
    "        real_batch = data[0].to(device)\n",
    "        fake_batch = dcgan.fake_batch(real_batch.size(0))\n",
    "        \n",
    "        errD = dcgan.discriminator_loss(real_batch, fake_batch)\n",
    "        \n",
    "        update_params(optimizerD, errD)\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        if errD.item() < .8 or g==0:\n",
    "            g += 1\n",
    "            fake_batch = dcgan.fake_batch(real_batch.size(0))\n",
    "            \n",
    "            errG = dcgan.generator_loss(real_batch, fake_batch)\n",
    "            \n",
    "            update_params(optimizerG, errG)\n",
    "\n",
    "        ###########################\n",
    "        # (3) save and print progress\n",
    "        ###########################\n",
    "#         # for progress prints\n",
    "#         D_x = output_real.mean().item()\n",
    "#         D_G_z1 = output_fake.mean().item()\n",
    "#         D_G_z2 = output.mean().item()\n",
    "        \n",
    "#         # Output training stats\n",
    "#         if i % 50 == 0:\n",
    "#             print('[{:0>2}/{:0>2}][{:0>4}/{:0>4}]  Loss_D: {:.3f}  Loss_G: {:.3f}  D(x): {:.3f}  D(G(z)): {:.3f} / {:.3f}  t={:6.3f}  iterG={}/50'.format(\n",
    "#                 epoch, num_epochs, i, len(trainLoader),errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, time.time()-current, g, prec=3))\n",
    "#             g = 0\n",
    "#             current = time.time()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('[{:0>4}/{:0>4}]  Loss_D: {:.3f}  Loss_G: {:.3f} t={:6.3f}'.format(\n",
    "                    i, len(trainLoader), errD, errG, time.time()-current, prec=3))\n",
    "            g = 0\n",
    "            current = time.time()\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "#         # Check how the generator is doing by saving G's output on fixed_noise\n",
    "#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(trainLoader)-1)):\n",
    "#             clear_output()\n",
    "#             with torch.no_grad():\n",
    "#                 fake = gen(fixed_noise).detach().cpu()\n",
    "#             img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qLtlQG2Cuq_d",
    "outputId": "65024124-694b-4d59-c352-6bb897e7496f"
   },
   "outputs": [],
   "source": [
    "len(G_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "8YYEjo5OkoEk",
    "outputId": "743943d3-b4f9-43b7-e529-d4e161320005"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\", alpha=.5)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxJ8XxdMsAJA"
   },
   "outputs": [],
   "source": [
    "trainIter = iter(trainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "Vx82QqQkply8",
    "outputId": "c12f4239-29b5-45c0-ce99-2f767b8c802c"
   },
   "outputs": [],
   "source": [
    "real_batch = next(trainIter)\n",
    "\n",
    "noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "fake = gen(noise).detach().cpu()\n",
    "fake = vutils.make_grid(fake, padding=2, normalize=True)\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(fake,(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJpr1lSsRHqv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_OKOGJwNm8a"
   },
   "outputs": [],
   "source": [
    "# print(optimizerD, optimizerG, trainLoader.batch_size, ngf, ndf, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8QwN3iUPoq6"
   },
   "outputs": [],
   "source": [
    "# genParams = gen.state_dict()\n",
    "# discParams = disc.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRqY8SLcINBM"
   },
   "outputs": [],
   "source": [
    "def dumpAndDL(variable, fileName):\n",
    "    with open(fileName, 'wb') as f:\n",
    "        pickle.dump(variable,\n",
    "                    f)\n",
    "        # files.download(fileName)\n",
    "        \n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiTt8Tx_RHq6"
   },
   "outputs": [],
   "source": [
    "# dumpAndDL(\n",
    "#     {'genParams': genParams,\n",
    "#      'discParams': discParams,\n",
    "#     },\n",
    "#     'bestParams.p'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtcYBxivRHq8"
   },
   "outputs": [],
   "source": [
    "dumpAndDL(\n",
    "    {'G_losses': G_losses,\n",
    "     'D_losses':D_losses,\n",
    "     },\n",
    "     'losses.p'\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpyuqMLnRHq_"
   },
   "outputs": [],
   "source": [
    "n=len(img_list)\n",
    "\n",
    "for idx, chunk in enumerate(chunks(img_list, n)):\n",
    "    fileName = 'img_list_{}.p'.format(idx)\n",
    "    dumpAndDL(\n",
    "        chunk,\n",
    "        fileName\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjn5p1v4RHrC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ieij_5kYRHrE"
   },
   "outputs": [],
   "source": [
    "# # load params to networks\n",
    "# fileName = 'bestParams.p'\n",
    "# netParams = None\n",
    "# with open(fileName, 'rb') as f:\n",
    "#      netParams = pickle.load(f)\n",
    "# gen.load_state_dict(netParams['genParams'])\n",
    "# disc.load_state_dict(netParams['discParams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtyEp0I3RHrG"
   },
   "outputs": [],
   "source": [
    "# # load params to networks\n",
    "# fileNames = ['img_list_0.p', 'img_list_1.p', 'img_list_2.p', 'img_list_3.p']\n",
    "\n",
    "# img_list = []\n",
    "# for fileName in fileNames:\n",
    "#     with open(fileName, 'rb') as f:\n",
    "#         img_list += pickle.load(f)['img_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8hNCrBaRHrJ"
   },
   "outputs": [],
   "source": [
    "# len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-wUyj_8KRHrM"
   },
   "outputs": [],
   "source": [
    "# #%%capture animation\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# plt.axis(\"off\")\n",
    "# ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list[:100]]\n",
    "# ani = animation.ArtistAnimation(fig, ims, interval=100, repeat_delay=1000, blit=True)\n",
    "\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# # writer = animation.writers['ffmpeg']\n",
    "# # ani.save('im.mp4', writer=writer, dpi=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dcgan_faster",
   "language": "python",
   "name": "dcgan_faster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
