{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1dqxpAkhj7nS"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import HTML\n",
        "\n",
        "import pickle\n",
        "# from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3h8mrtX8kBu8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torchvision.datasets import CIFAR10, MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xskxnRypkEud"
      },
      "outputs": [],
      "source": [
        "# Setting up constants\n",
        "# device\n",
        "ngpu = 2\n",
        "\n",
        "# single image\n",
        "imageSize = 64\n",
        "imageMean = (0.4923172 , 0.48307145, 0.4474483)\n",
        "imageStd = (0.24041407, 0.23696952, 0.25565723)\n",
        "\n",
        "# data loader\n",
        "numWorkers = 1\n",
        "batchSize = 8\n",
        "\n",
        "# Network Arch\n",
        "nc = 3 # Number of channels\n",
        "nz = 100 # Latent vector\n",
        "ngf = 128 # relates to the depth of feature maps carried through the generator\n",
        "ndf = 64 # sets the depth of feature maps propagated through the discriminator\n",
        "\n",
        "# Training\n",
        "num_epochs = 5\n",
        "\n",
        "# Adam Optimizer\n",
        "lr = .0005\n",
        "beta1 = .5\n",
        "\n",
        "# convention of the labeling for the real and the fake datasets\n",
        "real_label = .9\n",
        "fake_label = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_2Lp2upekCtM"
      },
      "outputs": [],
      "source": [
        "dataFolder = Path(\"./data\")\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RkXSbRAfkFw8"
      },
      "outputs": [],
      "source": [
        "# functions \n",
        "def visual_data(batch, device):\n",
        "    \"\"\"\n",
        "    Visualize a batch of image data\n",
        "    \n",
        "    Params\n",
        "    --------------------------------\n",
        "    batch:: a batch of images to visualize\n",
        "            in numpy matrix format\n",
        "            \n",
        "    device:: cpu/gpu device used for computations\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Training Images\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(batch[0].to(device)[:64], \n",
        "                                             padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "def load_mnist(mnistFolder, tsfms, batchSize=64, numWorkers=0):\n",
        "    \"\"\"\n",
        "    Load, download if necessary, the CIFAR10 data and \n",
        "    return the iterable batch generator object\n",
        "    \n",
        "    Params\n",
        "    --------------------------------\n",
        "    cifarFolder:: folder to store/load the CIFAR10 data from\n",
        "    tsfms:: transformations requaired to apply on data\n",
        "    batchSize:: number of samples on each batch of the data\n",
        "    numWorkers:: number of cpu cores used to load the data\n",
        "    \n",
        "    Return:\n",
        "    --------------------------------\n",
        "    trainLoader:: iterable training data batch generator object\n",
        "    testLoader:: iterable test data batch generator object\n",
        "    \"\"\"\n",
        "    trainData = MNIST(mnistFolder, download=True, train=True, transform=tsfms)\n",
        "    trainLoader = DataLoader(trainData, batch_size=batchSize, \n",
        "                             num_workers=numWorkers, shuffle=True)\n",
        "    \n",
        "    # testData = MNIST(mnistFolder, download=True, train=False, transform=tsfms)   \n",
        "    # testLoader = DataLoader(testData, batch_size=batchSize, num_workers=numWorkers)\n",
        "    \n",
        "    return trainLoader, testLoader\n",
        "\n",
        "def load_cifar10(cifarFolder, tsfms, batchSize=64, numWorkers=0):\n",
        "    \"\"\"\n",
        "    Load, download if necessary, the CIFAR10 data and \n",
        "    return the iterable batch generator object\n",
        "    \n",
        "    Params\n",
        "    --------------------------------\n",
        "    cifarFolder:: folder to store/load the CIFAR10 data from\n",
        "    tsfms:: transformations requaired to apply on data\n",
        "    batchSize:: number of samples on each batch of the data\n",
        "    numWorkers:: number of cpu cores used to load the data\n",
        "    \n",
        "    Return:\n",
        "    --------------------------------\n",
        "    trainLoader:: iterable training data batch generator object\n",
        "    testLoader:: iterable test data batch generator object\n",
        "    \"\"\"\n",
        "    trainData = CIFAR10(cifarFolder, download=True, train=True, transform=tsfms)\n",
        "    trainLoader = DataLoader(trainData, batch_size=batchSize, num_workers=numWorkers)\n",
        "    \n",
        "    testData = CIFAR10(cifarFolder, download=True, train=False, transform=tsfms)   \n",
        "    testLoader = DataLoader(testData, batch_size=batchSize, num_workers=numWorkers)\n",
        "    \n",
        "    return trainLoader, testLoader\n",
        "\n",
        "def weights_init(m):\n",
        "    \"\"\"\n",
        "    Custom weight initializer from the DCGAN papar\n",
        "    Different from the usual way of initializing the weigths\n",
        "    \n",
        "    Params:\n",
        "    -----------------------------------\n",
        "    m:: network object\n",
        "    \n",
        "    -----------------------------------\n",
        "    DCGAN paper arXiv:1511.06434 \n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DfZl2KzskG5j"
      },
      "outputs": [],
      "source": [
        "# the generator\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "knTrcyMZkH_M"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.features1 = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "        )\n",
        "\n",
        "        self.features2 = nn.Sequential(\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "        )\n",
        "        \n",
        "        self.classifier =  nn.Sequential(\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "      f1 = self.features1(input)\n",
        "      f2 = self.features2(f1)\n",
        "      cls = self.classifier(f2)\n",
        "      return cls, f1, f2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "colab_type": "code",
        "collapsed": true,
        "id": "PLRxbq3okJCs",
        "outputId": "d11272f6-5ac3-49de-d1d3-b8c151077e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "tsfms = transforms.Compose([\n",
        "    transforms.Resize(imageSize), \n",
        "\n",
        "    transforms.RandomHorizontalFlip(p=0.5), \n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imageMean, imageStd)\n",
        "])\n",
        "\n",
        "cifarFolder = dataFolder/\"CIFAR10\"\n",
        "\n",
        "trainLoader, test_loader = load_cifar10(cifarFolder, tsfms, batchSize, numWorkers)\n",
        "# trainLoader, test_loader = load_mnist(cifarFolder, tsfms, batchSize, numWorkers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mUk5fKx7kcG8"
      },
      "outputs": [],
      "source": [
        "gen = Generator(ngpu).to(device)\n",
        "gen.apply(weights_init);\n",
        "disc = Discriminator(ngpu).to(device)\n",
        "disc.apply(weights_init);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WkBmVf4QkjyB"
      },
      "outputs": [],
      "source": [
        "# BCE loss function\n",
        "criterion = nn.BCELoss()\n",
        "# feature matchin criterion\n",
        "feature_matching_criterion = nn.MSELoss()\n",
        "\n",
        "# fixed noise z for viusalization of the progress of the training\n",
        "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
        "\n",
        "# setup optmization \n",
        "optimizerD = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "2GYGcoKFkl5W",
        "outputId": "2be02a49-ab7a-4fc2-e48e-02f121996fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training Loop...\n"
          ]
        }
      ],
      "source": [
        "# training loop \n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "B_O1VRBwqiGd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "dgz = 0 \n",
        "\n",
        "bestGParams = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "colab_type": "code",
        "id": "7qFTS_GRkm8a",
        "outputId": "8fd7e5d4-1cf8-455b-ae2f-89c91e1a1b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0/5][3550/6250]\tLoss_D: 0.2804\tLoss_G: 2.2494\tD(x): 0.8286\tD(G(z)): 0.8697 / 0.0900\n",
            "[0/5][3600/6250]\tLoss_D: 0.1406\tLoss_G: 1.0802\tD(x): 0.5669\tD(G(z)): 0.4257 / 0.3225\n",
            "[0/5][3650/6250]\tLoss_D: 0.1355\tLoss_G: 1.6686\tD(x): 0.5467\tD(G(z)): 0.3498 / 0.1666\n",
            "[0/5][3700/6250]\tLoss_D: 0.1799\tLoss_G: 1.5189\tD(x): 0.7248\tD(G(z)): 0.6566 / 0.1966\n",
            "[0/5][3750/6250]\tLoss_D: 0.1667\tLoss_G: 1.2044\tD(x): 0.5136\tD(G(z)): 0.5057 / 0.2831\n",
            "[0/5][3800/6250]\tLoss_D: 0.1407\tLoss_G: 1.0321\tD(x): 0.5211\tD(G(z)): 0.4275 / 0.3336\n",
            "[0/5][3850/6250]\tLoss_D: 0.1607\tLoss_G: 1.8322\tD(x): 0.7377\tD(G(z)): 0.5934 / 0.1392\n",
            "[0/5][3900/6250]\tLoss_D: 0.1477\tLoss_G: 1.7246\tD(x): 0.6535\tD(G(z)): 0.5233 / 0.1542\n",
            "[0/5][3950/6250]\tLoss_D: 0.1333\tLoss_G: 1.7599\tD(x): 0.6520\tD(G(z)): 0.4495 / 0.1512\n"
          ]
        }
      ],
      "source": [
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the trainLoader\n",
        "    for i, data in enumerate(trainLoader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        disc.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label_real = torch.full((b_size,), real_label, device=device)\n",
        "        # Forward pass real batch through D\n",
        "        output_real, feat_real1, feat_real2 = disc(real_cpu)\n",
        "        output_real = output_real.view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output_real, label_real)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        \n",
        "        D_x = output_real.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "\n",
        "        # Generate fake image batch with G\n",
        "        fake = gen(noise)\n",
        "        label_fake = torch.full((b_size,), fake_label, device=device)\n",
        "        # Classify all fake batch with D\n",
        "        output_fake, feat_fake1, feat_fake2 = disc(fake.detach())\n",
        "        output_fake = output_fake.view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output_fake, label_fake)\n",
        "        # Calculate the gradients for this batch\n",
        "        \n",
        "        D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "        # feat matching errors\n",
        "        feat_real1 = feat_real1.detach()  # so that PyTorch will treat them as volatile\n",
        "        feat_real2 = feat_real2.detach()  # so that PyTorch will treat them as volatile\n",
        "        fm_loss1 = feature_matching_criterion(feat_fake1, feat_real1)\n",
        "        fm_loss2 = feature_matching_criterion(feat_fake1, feat_real1)\n",
        "\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = 1 / 10 * (errD_real + errD_fake) + 6 / 10 * fm_loss1 + 3 / 10 * fm_loss2\n",
        "        # errD = fm_loss\n",
        "\n",
        "        # errD_real.backward()\n",
        "        # errD_fake.backward()\n",
        "        errD.backward()\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        gen.zero_grad()\n",
        "        label = torch.full((b_size,), real_label, device=device)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output, _, _ = disc(fake)\n",
        "        output = output.view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(trainLoader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(trainLoader)-1)):\n",
        "            clear_output()\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qLtlQG2Cuq_d"
      },
      "outputs": [],
      "source": [
        "len(G_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8YYEjo5OkoEk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gxJ8XxdMsAJA"
      },
      "outputs": [],
      "source": [
        "trainIter = iter(trainLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Vx82QqQkply8"
      },
      "outputs": [],
      "source": [
        "real_batch = next(trainIter)\n",
        "\n",
        "noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "fake = gen(noise).detach().cpu()\n",
        "fake = vutils.make_grid(fake, padding=2, normalize=True)\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(fake,(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Y_OKOGJwNm8a"
      },
      "outputs": [],
      "source": [
        "print(optimizerD, optimizerG, trainLoader.batch_size, ngf, ndf, real_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-8QwN3iUPoq6"
      },
      "outputs": [],
      "source": [
        "genParams = gen.state_dict()\n",
        "discParams = disc.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lRqY8SLcINBM"
      },
      "outputs": [],
      "source": [
        "def dumpAndDL(variable, fileName):\n",
        "    with open(fileName, 'wb') as f:\n",
        "        pickle.dump(variable,\n",
        "                    f)\n",
        "        files.download(fileName)\n",
        "        \n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gp7mrdFQ7VRc"
      },
      "outputs": [],
      "source": [
        "dumpAndDL(\n",
        "    {'genParams': genParams,\n",
        "     'discParams': discParams,\n",
        "    },\n",
        "    'bestParams.p'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3ZWKNWTS7VRg"
      },
      "outputs": [],
      "source": [
        "dumpAndDL(\n",
        "    {'G_losses': G_losses,\n",
        "     'D_losses':D_losses,\n",
        "     },\n",
        "     'losses.p'\n",
        "       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A02smzyP7VRi"
      },
      "outputs": [],
      "source": [
        "n=50\n",
        "for idx, chunk in enumerate(chunks(img_list, n)):\n",
        "    fileName = 'img_list_{}.p'.format(idx)\n",
        "    dumpAndDL(\n",
        "        chunk,\n",
        "        fileName\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_T1xfKKh7VRl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KQ7mkw5K7VRo"
      },
      "outputs": [],
      "source": [
        "# # load params to networks\n",
        "# fileName = 'bestParams.p'\n",
        "# netParams = None\n",
        "# with open(fileName, 'rb') as f:\n",
        "#      netParams = pickle.load(f)\n",
        "# gen.load_state_dict(netParams['genParams'])\n",
        "# disc.load_state_dict(netParams['discParams'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vfFebnxq7VRr"
      },
      "outputs": [],
      "source": [
        "# load params to networks\n",
        "fileNames = ['img_list_0.p', 'img_list_1.p', 'img_list_2.p', 'img_list_3.p']\n",
        "\n",
        "img_list = []\n",
        "for fileName in fileNames:\n",
        "    with open(fileName, 'rb') as f:\n",
        "        img_list += pickle.load(f)['img_list']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Xqlb56Ao7VRu"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=100, repeat_delay=1000, blit=True)\n",
        "\n",
        "# HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2MIEslME7VRx"
      },
      "outputs": [],
      "source": [
        "Writer = animation.writers['ffmpeg']\n",
        "ani.save('im.mp4', writer=writer)"
      ]
    }
  ]
}